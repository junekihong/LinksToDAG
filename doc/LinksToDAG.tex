%
% File acl2014.tex
%
% Contact: koller@ling.uni-potsdam.de, yusuke@nii.ac.jp
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{LinksToDAG}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{soul}
\newcommand{\Note}[1]{}
\renewcommand{\Note}[1]{\hl{[#1]}}  % comment out this definition to suppress all Notes                                                                                
\newcommand{\TODO}[1]{\Note{TODO: #1}}
\newcommand{\NoteSigned}[3]{{\sethlcolor{#2}\Note{#1: #3}}}
\newcommand{\NoteJE}[1]{\NoteSigned{JE}{LightBlue}{#1}}
\newcommand{\NoteJH}[1]{\NoteSigned{JH}{YellowGreen}{#1}}


\title{Deriving Multi-headed Planar Dependency Parses from Link Grammar Parses}

\author{Juneki Hong and Jason Eisner\\
  Department of Computer Science \\
  Johns Hopkins University \\
  Baltimore, MD 21218, USA \\ 
  {\tt \{juneki,jason\}@cs.jhu.edu} \\
}

\date{}

\begin{document}
\maketitle

\begin{abstract}

% Copied from the google doc
There has been recent theoretical work on multi-headed versions of dependency grammar (cite). Such formalisms can be more syntactically and semantically expressive. However, there aren't any corpora at present (check this) except for Buch-Kromann's work on Danish (cite), so it is hard to investigate the benefit of such parsers or to work on making them faster or more accurate. To fill this gap, we observe that link grammar produces parses that are similar to multi-headed planar dependency parses except that the links are undirected. We use Integer Linear Programming to assign consistent directions to the links in a corpus of NNN parses produced by the Link Grammar Parser, which has broad-coverage hand-written grammars of English, Arabic, and ... (what statistics does it use?). We find that such directions can indeed be consistently assigned in a way that yields valid multi-headed dependency parses. The resulting parses in English appear linguistically plausible, although they are not in general consistent with CoNLL-style parses of the same sentences; we discuss the differences. We also report ...

\end{abstract}




\section{Introduction}



Dependency Parsing is the task of mapping a sentence to a projective (not always projective?) directed acyclic tree. Link Parsing in contrast produces a planar graph with undirected edges, where every edge has a label. The labels describe the relationship between two constituents in a parse, and in this paper we will analyze whether this includes dependencies as well. In order to learn the directional dependencies within the Link edge labels we will use Integer Linear Programming, encoding the problem in the Zimpl little language \cite{Koch2004}. 



\section{Link Grammars}

Link Grammars are a formalism that describes the links, or relationships between the constituents \cite{SleatorTemperly91}. 


We ran the link parser on the english bnews corpus sentences \footnote{We ignored the link parses that the link parser could not find suitable attachments and returned a disconnected graph. This happened for roughly NNN\% of the corpus.}


The link grammar on which the link-parser makes its linking decisions based on a set of handwritten dictionaries. Instead of going through these dictionaries, we learned the link grammar using an ILP. This approach allows us to analyze any link grammar dictionary other than English.


\section{Integer Linear Programming}

We formulated the ILP to assign directional dependencies to a link grammar parse such that it is a connected DAG, with all of the nodes reachable from the root.

The ILP chooses whether to set a link type to be assigned left, right, or both. For this, two label\_direction variables were made for each link type that appears in the parses, corresponding to whether all of the $l$ link edges were to be set to go left, right, or both. Because we assign a directionality to every link type, at least one of these variables must be set to true.

For example, setting the variables $$l_{LEFT} = TRUE, l_{RIGHT} = FALSE$$ would mean that the directional dependency of all links with label $l$ would be set to $LEFT$. If both variables were set to true, then the link type is allowed to go in either direction. Our ILP objective is to minimize the number of label\_direction variables set to true, while satisfying the other constraints.



\subsection{Slack Hierarchy}

We introduced slack on the directional dependency variable tokens such that link types were allowed to deviate from the majority up to (1\% ?) of the time before the ILP would assign both directional dependency variables to true. This addressed noise in the link parser's label assignments, while still allowing for the possibility that both directions could still be assigned.

\TODO{} We also introduced slack on the link types such that link types with the same coarse grained label would try and align the same way as the majority in the group, where the preceding capital letters of the link type denote the coarse grained label, while the subscript letters denote further information. This slack places a prior on rare or never-before seen link types to be assigned in the same way as other similar link types.

This slack hierarchy gave the ILP the flexibility to handle noise and novel link types while still trying to learn the overall link grammar.




\begin{algorithm}
\caption{ILP Encoding}\label{ILP}
\begin{algorithmic}[1]
%\Procedure{MyProcedure}{}

\State $\text{min} \sum_{l \in labels} allowed_L(l) + allowed_R(l)$
\State $\text{subject to}$

%\EndProcedure
\end{algorithmic}
\end{algorithm}



\subsection{Stability of Results}
We tested to see how the solution changed as we increased the number of processed sentences. Taking the largest run as the answer key, we analyzed how much the previous runs deviated from it. We measured the precision of whether the assignments in the smaller runs matched the assignments of the largest run, and we measured the recall of whether the assignments in the largest run could be found in the smaller runs. 


\includegraphics[width=\linewidth, keepaspectratio=true]{figure/precision_recall.png}



\section{Other languages}


\section{Conll-Link analysis}




\section{Related Work}

\TODO {abc} def



\section{Results}


\section{Discussion}




\bibliographystyle{LinksToDAG}
\bibliography{LinksToDAG}

\end{document}
